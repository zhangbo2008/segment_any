# %% [markdown]  # github :别人的训练版代码.  https://github.com/Shaneey198/Segmentation
# ## Load model weights ============测试.
from segment_anything import build_sam, SamAutomaticMaskGenerator, sam_model_registry
pat='/mnt/e/sam_vit_b_01ec64.pth'
from segment_anything import build_sam, SamAutomaticMaskGenerator, sam_model_registry
if 0:
    
    # %%
    from segment_anything import build_sam, SamAutomaticMaskGenerator, sam_model_registry
    mask_generator = SamAutomaticMaskGenerator(build_sam(checkpoint=pat))
    testing_image = 'demo.jpg'
    masks = mask_generator.generate()






#=================重新加载模型.
# %%
sam_model = sam_model_registry["vit_b"](checkpoint=pat)

# %% [markdown]
# ## Training model

# %%
import torch
import torchvision.models as models
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
from torchvision.transforms import transforms

# Define the transforms
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Define the dataset and dataloader for the input images
pp='BIG'
dataset = ImageFolder(pp, transform=transform)
dataloader = DataLoader(dataset, batch_size=1, shuffle=True) # batch设置为1, 这样不同图片尺寸的就不用提前对齐了.

# Adjust the model architecture to handle large input size
# sam_model.backbone.conv1 = nn.Conv2d(3, 2048, kernel_size=35, stride=3, padding=3, bias=False)

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()#=========这个损失跟论文都不太对.#先跑通代码然后再改细节.
optimizer = optim.Adam(sam_model.parameters(), lr=0.0001)

# Train the model on the large dataset with image size of 5000x3600
for epoch in range(10):
    for i, data in enumerate(dataloader):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = sam_model(inputs)
        loss = criterion(outputs['out'], labels)
        loss.backward()
        optimizer.step()
        print('Epoch: {}, Batch: {}, Loss: {}'.format(epoch, i, loss.item()))

# Save the trained model
torch.save(sam_model.state_dict(), 'models/sam_model.pth')


